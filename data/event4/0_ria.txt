Хокинг: супер-умный ИИ будет смотреть на людей, как на муравьев | РИА Новости
Британский астрофизик Стивен Хокинг объяснил читателям Reddit, почему он выступает против "гонки ИИ" и создания сверхразумных машин, и рассказал о том, чем грозит замена всех рабочих на роботов.'
МОСКВА, 9 окт &ndash; РИА Новости.</strong> Известный британский космолог Стивен Хокинг объяснил свое неприятие технологий искусственного интеллекта &ndash; по&nbsp;его мнению, сверхразумные машины будут смотреть на&nbsp;людей, как&nbsp;на расходный материал или&nbsp;муравьев, мешающих решению поставленной перед ними задачи.</p>
<p>Общаясь с&nbsp;пользователями портала <a href="https://www.reddit.com/comments/3eret9/" target="_blank">Reddit</a>, Хокинг подчеркнул, что он не&nbsp;считает подобные машины "злыми" существами, желающими уничтожить человечество из-за интеллектуального превосходства над&nbsp;нами. Скорее, они просто не&nbsp;будут замечать человечество.</p>
<p>"СМИ постоянно искажают мои слова. Главный риск от&nbsp;развития ИИ заключается не&nbsp;в их злобе, а&nbsp;в компетенции. Сверхумный ИИ будет очень хорошо справляться с&nbsp;задачами, и&nbsp;если его и&nbsp;наши цели не&nbsp;будут совпадать, у&nbsp;нас будут огромные проблемы",&nbsp;&mdash; объясняет ученый.
<p>В качестве примера Хокинг привел гипотетическую ситуацию, в&nbsp;которой мощный искусственный интеллект управляет работой или&nbsp;постройкой новой плотины ГЭС. Для такой машины в&nbsp;первую очередь будет важно то, как&nbsp;много энергии вырабатывает вверенная ей система, а&nbsp;судьбы людей будут иметь для&nbsp;нее никакого значения.</p>
<p>"Среди нас мало людей, кто топчет муравейники и&nbsp;наступает на&nbsp;муравьев со&nbsp;злости, но&nbsp;представьте ситуацию &ndash; вы контролируете ГЭС, вырабатывающую электроэнергию. Если вам нужно поднять уровень воды и&nbsp;в результате этого один муравейник будет затоплен, то проблемы утопающих насекомых вас вряд ли будут беспокоить. Давайте не&nbsp;ставить людей на&nbsp;место подобных муравьев",&nbsp;&mdash; продолжает космолог.</p>
<p>Другой потенциальной проблемой от&nbsp;дальнейшего развития систем ИИ и&nbsp;роботехники может стать то, что Хокинг называет "тиранией хозяев машин" &ndash; стремительный рост разрыва в&nbsp;уровне доходов между богатыми людьми, монополизировавшими производство разумных машин, и&nbsp;остальными слоями населения Земли.</p>
<p>Хокинг предлагает решить эти ситуации двумя путями &ndash; замедлив разработку ИИ и&nbsp;переключившись на&nbsp;создание не "универсального", а&nbsp;узкоспециализированного искусственного разума, способного решать крайне ограниченный круг задач.</p>